# -*- coding: utf-8 -*-
"""AshleyBrooks_DS21_ LS_DS_112_Make_Features_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_6YvK_OUMUBj34QeatgyGVyLhZlQb0g_

Lambda School Data Science

*Unit 1, Sprint 1, Module 2*

---

# Learning Objectives

- Student should be able to understand the purpose of feature engineering
- Student should be able to work with strings in pandas
- Student should be able to work with dates and times in pandas
- Student should be able to modify or create columns of a dataframe using the `.apply()` function


Helpful Links:
- [Minimally Sufficient Pandas](https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428)
- [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering)
- Python Data Science Handbook
  - [Chapter 3.10](https://jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html), Vectorized String Operations
  - [Chapter 3.11](https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html), Working with Time Series
- [Lambda Learning Method for DS - By Ryan Herr](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit?usp=sharing)

# Let's continue to explore feature engineering with the Ames Housing data.  Import the dataset and name it "house".

###1) Import the Ames Housing Data here: https://raw.githubusercontent.com/ryanleeallred/datasets/master/Ames%20Housing%20Data/train.csv
"""

#Code here

import pandas as pd

house = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/Ames%20Housing%20Data/train.csv')

"""###2) Print the first five rows of the house dataset."""

#Code here

house.head()

"""###3) Create a new variable called Large_Lot that takes on the value 1 when LotArea is gerater than or equal to 10,000 and the value 0 when LotArea is less than 10,000."""

#Code here
def LotAreaValue(x):
  for l in house['LotArea']:
    if ( l >= 10,000):
      return 1
    else: 
      return 0

house['Large_Lot']= house['LotArea'].apply(LotAreaValue)

house['Large_Lot'].head()

"""###4) Create a new variable called Total_Bathrooms that contains the total number of full and half bathrooms in the house."""

#Code here

Total_Bathrooms = (house['BsmtFullBath'].sum()) + (house['BsmtHalfBath'].sum()) + (house['FullBath'].sum()) + (house['HalfBath'].sum())
print(Total_Bathrooms)

"""###5) Create a new variable called Summer_Sale that equals 1 if the sale month was in June, July or August ( MoSold = 6, 7 or 8) and 0 if the sale month was in September - May."""

#code here
#def summer(y):
 # for m in house['MoSold']:
  #  if (df['m'] ==6) & (df['m']==7) & (df['m']==8):
   #   return 1
    #else:
     # return 0

#house['Summer_Sale']= house['MoSold'].apply(summer)

def summer(y):
  if y == 6:
    return 1
  elif y==7:
    return 1
  elif y==8:
    return 1
  else:
    return 0

house['Summer_Sale']= house['MoSold'].apply(summer)

house['Summer_Sale'].head()

"""#Now we'll revisit the LendingClub data.

Remember to import the data by first unzipping the file:
"""

!wget https://resources.lendingclub.com/LoanStats_2018Q4.csv.zip

!unzip LoanStats_2018Q4.csv.zip

# Read in the CSV
import pandas as pd
df = pd.read_csv('LoanStats_2018Q4.csv', skiprows=1, skipfooter=2, engine='python')

print(df.shape)
df

"""#Approaching a problem two different ways.

In the guided project, we learned how to find the earliest credit year using the built-in pandas date-time format.  However, there is often more than one way to come up with the same solution.

In the following questions we will work through the steps to create a new variables called Earliest_Credit_Year and issue_year where we use the .split() function remove the month report back just the year as a float data type.  Then we'll use those variables to calculate the length of credit history in years.

If we do everything correctly, we should calculate *about* the same length of longest credit history that we did in class working with the date-time format.  The answers won't exactly match because we are making different assumptions about when in each month and year the loans were taken out, but it will give you a flavor for different ways of approaching the same problem.

###6) Create a simple test case where credit = 'Jun-1979'.  

Use the .split('-') function to separate the month and year parts of the data and print the year.

Hint: Name the results of the .split('-') function "fields".  fields[0] will return the month part of the date and fields[1] will return the year part of the date.
"""

#code here
import pandas as pd
import numpy as np
#Earliest_Credit_Year=df['earliest_cr_line'].min()
#Earliest_Credit_Year.split('-')
#fields = df['earliest_cr_line']
#fields.split('-')

#print(df['earliest_cr_line'].split('-'))
df['fields'] = pd.to_datetime(df['earliest_cr_line'], infer_datetime_format=True)
df['fields'].dt.month
df['fields'].dt.year

fields=df['fields'].dt.month, df['fields'].dt.year
fields[0]
fields [1]

#fields=df['earliest_cr_line'].split('-')



#fields.split('-')

"""###7) Use your answer in 6) to write a function called credit_yr that takes in the contents of a cell formatted 'month-year' and returns the year.

Run your function using the simple test case in 6).
"""

#Code here

def credit_yr(m):
  df['year'] = pd.DatetimeIndex(df['earliest_cr_line']).year
  return df['year']

"""###8) Use the .apply() function to apply the function to every cell in the earliest_cr_line variable."""

#code here

df['earliest_cr_line'].apply(credit_yr)

"""###9) Print the top 5 rows of the Earliest_Credit_Year and earliest_cr_line variables to make sure the variables were created correctly."""

#code here

Earliest_Credit_Year= df['fields'].dt.year

print(Earliest_Credit_Year.head())
print(df['earliest_cr_line'].head())

"""### 10) Use your function to create a new variable called Issue_Year from the issue_d variable."""

#code here

#I COULD NOT FIGURE OUT HOW TO CREATE A FUNCTION
##ITS TOO LATE TO ASK FOR HELP. I WILL ASK TOORROW DURING Q&A. 
###I'M PRETTY LOST ON THAT ONE
df['Issue_Year']= pd.to_datetime(df['issue_d'], infer_datetime_format=True)
df['Issue_Year'] =df['Issue_Year'].dt.year

df['Issue_Year'].head()

"""###11) Caluculate length of credit history in years and in days.

Hint: If you are getting an error message, make sure to check the data type of the years output by your functions.
"""

#Code here

df['earliest_cr_line'] = pd.to_datetime(df['earliest_cr_line'], infer_datetime_format=True)
df['issue_d']= pd.to_datetime(df['issue_d'],infer_datetime_format=True )
df['Credit_Hist'] = df['issue_d'] - df['earliest_cr_line']

df['Credit_Hist']

"""###12) Calculate the maximum credit length and compare it to we got in the guided project.  

Note - it won't be *exactly* the same because both methods are working in different ways, but they will give you a "pretty close" answer.
"""

#code here
df['Credit_Hist'].max()

"""#Portfolio Project Assignment

Start looking for interesting datasets!  

Pretty much every major US governmental agency (CDC, Bureau of Labor Statistics, The Census, etc.) maintains a treasure trove of data.

There's also:

Datasets from the University of Florida Department of Statistics: http://users.stat.ufl.edu/~winner/datasets.html

Pew Research: https://www.pewresearch.org/

General Social Survey: https://gss.norc.org/

Ancestry.com Free data collections: https://www.ancestry.com/search/categories/freeindexacom/?clickref=1101lbhdWxys&key=Uhttps%3A%2F%2Fwww.ancestry.com%2Fsearch%2Fcategories%2Ffreeindexacom%2F%3Fclickref%3D1101lbhdWxys&o_lid=01011l4pVw&o_sch=Affiliate+External&o_xid=01011l4pVw

Popular baby names by year since the founding of the SSA: https://www.babynamewizard.com/ 


https://data.world/

https://www.kaggle.com/datasets

https://catalog.data.gov/dataset

https://datasetsearch.research.google.com/

https://archive.ics.uci.edu/ml/index.php

https://github.com/plotly/datasets

https://lionbridge.ai/datasets/20-best-image-datasets-for-computer-vision/

https://www.visualdata.io/

https://pathmind.com/wiki/open-datasets

https://blog.playment.io/top-open-image-dataset/

https://blog.cambridgespark.com/

https://www.analyticsvidhya.com/blog/2018/03/

https://data-flair.training/blogs/machine-learning-datasets/






"""